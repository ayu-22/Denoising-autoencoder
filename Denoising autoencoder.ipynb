{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Denoising autoencoder.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"JhWl6jNdWFXZ","colab_type":"code","colab":{}},"source":["import keras\n","from keras.layers import Activation, Dense, Input\n","from keras.layers import Conv2D, Flatten\n","from keras.layers import Reshape, Conv2DTranspose\n","from keras.models import Model\n","from keras import backend as K\n","from keras.datasets import mnist\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from keras.layers import *\n","from keras.callbacks import ReduceLROnPlateau"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"8c9KPFqMWV7j","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":879},"outputId":"024b663c-9cf4-4b71-aef3-5b017ced1187","executionInfo":{"status":"ok","timestamp":1563226316387,"user_tz":-330,"elapsed":1431,"user":{"displayName":"ayush singh","photoUrl":"","userId":"03115614203563270282"}}},"source":["encoder_i = Input(shape = (28,28,1))\n","encoder = Conv2D(16, (3,3), activation='relu', padding='same', strides=2)(encoder_i)\n","encoder = Conv2D(16, (3,3), activation='relu', padding='same', strides=1)(encoder)\n","encoder = BatchNormalization()(encoder)\n","encoder = Conv2D(32, (3,3), activation='relu', padding='same', strides=2)(encoder)\n","encoder = Conv2D(32, (3,3), activation='relu', padding='same', strides=1)(encoder)\n","encoder = BatchNormalization()(encoder)\n","encoder = Flatten()(encoder)\n","encoder = Dense(8*7*7, activation='relu')(encoder)\n","encoder = Dense(100, activation = 'relu')(encoder)\n","\n","decoder = Dense(8*7*7, activation = 'relu')(encoder)\n","decoder = Dense(32*7*7, activation = 'relu')(decoder)\n","decoder = Reshape((7, 7, 32))(decoder)\n","decoder = Conv2D(32, (3,3), activation='relu', padding='same', strides=1)(decoder)\n","decoder = BatchNormalization()(decoder)\n","decoder = UpSampling2D((2,2))(decoder)\n","decoder = Conv2D(16, (3,3), activation='relu', padding='same', strides=1)(decoder)\n","decoder = Conv2D(16, (3,3), activation='relu', padding='same', strides=1)(decoder)\n","decoder = BatchNormalization()(decoder)\n","decoder = UpSampling2D((2,2))(decoder)\n","decoder = Conv2D(1, (3,3), activation='relu', padding='same', strides=1)(decoder)\n","\n","model = Model(inputs = encoder_i, outputs = decoder)\n","adam = keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n","model.compile(optimizer=adam, loss='mse')\n","model.summary()\n"],"execution_count":75,"outputs":[{"output_type":"stream","text":["_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_9 (InputLayer)         (None, 28, 28, 1)         0         \n","_________________________________________________________________\n","conv2d_58 (Conv2D)           (None, 14, 14, 16)        160       \n","_________________________________________________________________\n","conv2d_59 (Conv2D)           (None, 14, 14, 16)        2320      \n","_________________________________________________________________\n","batch_normalization_29 (Batc (None, 14, 14, 16)        64        \n","_________________________________________________________________\n","conv2d_60 (Conv2D)           (None, 7, 7, 32)          4640      \n","_________________________________________________________________\n","conv2d_61 (Conv2D)           (None, 7, 7, 32)          9248      \n","_________________________________________________________________\n","batch_normalization_30 (Batc (None, 7, 7, 32)          128       \n","_________________________________________________________________\n","flatten_8 (Flatten)          (None, 1568)              0         \n","_________________________________________________________________\n","dense_31 (Dense)             (None, 392)               615048    \n","_________________________________________________________________\n","dense_32 (Dense)             (None, 100)               39300     \n","_________________________________________________________________\n","dense_33 (Dense)             (None, 392)               39592     \n","_________________________________________________________________\n","dense_34 (Dense)             (None, 1568)              616224    \n","_________________________________________________________________\n","reshape_8 (Reshape)          (None, 7, 7, 32)          0         \n","_________________________________________________________________\n","conv2d_62 (Conv2D)           (None, 7, 7, 32)          9248      \n","_________________________________________________________________\n","batch_normalization_31 (Batc (None, 7, 7, 32)          128       \n","_________________________________________________________________\n","up_sampling2d_15 (UpSampling (None, 14, 14, 32)        0         \n","_________________________________________________________________\n","conv2d_63 (Conv2D)           (None, 14, 14, 16)        4624      \n","_________________________________________________________________\n","conv2d_64 (Conv2D)           (None, 14, 14, 16)        2320      \n","_________________________________________________________________\n","batch_normalization_32 (Batc (None, 14, 14, 16)        64        \n","_________________________________________________________________\n","up_sampling2d_16 (UpSampling (None, 28, 28, 16)        0         \n","_________________________________________________________________\n","conv2d_65 (Conv2D)           (None, 28, 28, 1)         145       \n","=================================================================\n","Total params: 1,343,253\n","Trainable params: 1,343,061\n","Non-trainable params: 192\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"UTp8gz87aCn2","colab_type":"code","colab":{}},"source":["lr_red = ReduceLROnPlateau(monitor = 'val_loss',\n","                           patience = 5,\n","                           verbose = 1,\n","                           factor = 0.5,\n","                           min_lr = 0.0000000001\n","                           )"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"u8hM6etQYjsj","colab_type":"code","colab":{}},"source":["(x_train, _), (x_test, _) = mnist.load_data()\n","\n","x_train = x_train/255\n","x_test = x_test/255\n","\n","train = x_train[:1000]\n","\n","noise = np.random.normal(0.2,0.1,(train.shape))\n","noisy_train = train+noise\n","\n","train = train.reshape(1000,28,28,1)\n","noisy_train = noisy_train.reshape(1000,28,28,1)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"gn9pB7fVZ2xH","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"ebf26191-b6e8-49a0-841d-d981945acbd7","executionInfo":{"status":"ok","timestamp":1563226402301,"user_tz":-330,"elapsed":79212,"user":{"displayName":"ayush singh","photoUrl":"","userId":"03115614203563270282"}}},"source":["model.fit(noisy_train,\n","          train,\n","          epochs = 200,\n","          validation_split = 0.1,\n","          callbacks = [lr_red]\n","         )"],"execution_count":76,"outputs":[{"output_type":"stream","text":["Train on 900 samples, validate on 100 samples\n","Epoch 1/200\n","900/900 [==============================] - 4s 5ms/step - loss: 0.1501 - val_loss: 0.1677\n","Epoch 2/200\n","900/900 [==============================] - 0s 403us/step - loss: 0.0644 - val_loss: 0.0660\n","Epoch 3/200\n","900/900 [==============================] - 0s 391us/step - loss: 0.0517 - val_loss: 0.0488\n","Epoch 4/200\n","900/900 [==============================] - 0s 391us/step - loss: 0.0435 - val_loss: 0.0456\n","Epoch 5/200\n","900/900 [==============================] - 0s 405us/step - loss: 0.0383 - val_loss: 0.0412\n","Epoch 6/200\n","900/900 [==============================] - 0s 388us/step - loss: 0.0339 - val_loss: 0.0399\n","Epoch 7/200\n","900/900 [==============================] - 0s 396us/step - loss: 0.0303 - val_loss: 0.0346\n","Epoch 8/200\n","900/900 [==============================] - 0s 414us/step - loss: 0.0272 - val_loss: 0.0342\n","Epoch 9/200\n","900/900 [==============================] - 0s 396us/step - loss: 0.0248 - val_loss: 0.0304\n","Epoch 10/200\n","900/900 [==============================] - 0s 401us/step - loss: 0.0226 - val_loss: 0.0272\n","Epoch 11/200\n","900/900 [==============================] - 0s 409us/step - loss: 0.0207 - val_loss: 0.0278\n","Epoch 12/200\n","900/900 [==============================] - 0s 393us/step - loss: 0.0192 - val_loss: 0.0245\n","Epoch 13/200\n","900/900 [==============================] - 0s 401us/step - loss: 0.0188 - val_loss: 0.0246\n","Epoch 14/200\n","900/900 [==============================] - 0s 386us/step - loss: 0.0172 - val_loss: 0.0236\n","Epoch 15/200\n","900/900 [==============================] - 0s 384us/step - loss: 0.0167 - val_loss: 0.0227\n","Epoch 16/200\n","900/900 [==============================] - 0s 398us/step - loss: 0.0156 - val_loss: 0.0208\n","Epoch 17/200\n","900/900 [==============================] - 0s 398us/step - loss: 0.0149 - val_loss: 0.0217\n","Epoch 18/200\n","900/900 [==============================] - 0s 387us/step - loss: 0.0157 - val_loss: 0.0230\n","Epoch 19/200\n","900/900 [==============================] - 0s 406us/step - loss: 0.0147 - val_loss: 0.0207\n","Epoch 20/200\n","900/900 [==============================] - 0s 400us/step - loss: 0.0135 - val_loss: 0.0198\n","Epoch 21/200\n","900/900 [==============================] - 0s 409us/step - loss: 0.0129 - val_loss: 0.0188\n","Epoch 22/200\n","900/900 [==============================] - 0s 400us/step - loss: 0.0123 - val_loss: 0.0201\n","Epoch 23/200\n","900/900 [==============================] - 0s 394us/step - loss: 0.0123 - val_loss: 0.0186\n","Epoch 24/200\n","900/900 [==============================] - 0s 398us/step - loss: 0.0124 - val_loss: 0.0201\n","Epoch 25/200\n","900/900 [==============================] - 0s 405us/step - loss: 0.0119 - val_loss: 0.0183\n","Epoch 26/200\n","900/900 [==============================] - 0s 388us/step - loss: 0.0116 - val_loss: 0.0185\n","Epoch 27/200\n","900/900 [==============================] - 0s 392us/step - loss: 0.0107 - val_loss: 0.0182\n","Epoch 28/200\n","900/900 [==============================] - 0s 411us/step - loss: 0.0106 - val_loss: 0.0180\n","Epoch 29/200\n","900/900 [==============================] - 0s 393us/step - loss: 0.0104 - val_loss: 0.0179\n","Epoch 30/200\n","900/900 [==============================] - 0s 393us/step - loss: 0.0103 - val_loss: 0.0174\n","Epoch 31/200\n","900/900 [==============================] - 0s 409us/step - loss: 0.0098 - val_loss: 0.0174\n","Epoch 32/200\n","900/900 [==============================] - 0s 395us/step - loss: 0.0096 - val_loss: 0.0169\n","Epoch 33/200\n","900/900 [==============================] - 0s 393us/step - loss: 0.0096 - val_loss: 0.0178\n","Epoch 34/200\n","900/900 [==============================] - 0s 402us/step - loss: 0.0094 - val_loss: 0.0170\n","Epoch 35/200\n","900/900 [==============================] - 0s 389us/step - loss: 0.0091 - val_loss: 0.0190\n","Epoch 36/200\n","900/900 [==============================] - 0s 414us/step - loss: 0.0099 - val_loss: 0.0177\n","Epoch 37/200\n","900/900 [==============================] - 0s 392us/step - loss: 0.0091 - val_loss: 0.0172\n","\n","Epoch 00037: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n","Epoch 38/200\n","900/900 [==============================] - 0s 388us/step - loss: 0.0079 - val_loss: 0.0160\n","Epoch 39/200\n","900/900 [==============================] - 0s 391us/step - loss: 0.0072 - val_loss: 0.0155\n","Epoch 40/200\n","900/900 [==============================] - 0s 403us/step - loss: 0.0071 - val_loss: 0.0161\n","Epoch 41/200\n","900/900 [==============================] - 0s 390us/step - loss: 0.0072 - val_loss: 0.0160\n","Epoch 42/200\n","900/900 [==============================] - 0s 389us/step - loss: 0.0068 - val_loss: 0.0158\n","Epoch 43/200\n","900/900 [==============================] - 0s 396us/step - loss: 0.0068 - val_loss: 0.0160\n","Epoch 44/200\n","900/900 [==============================] - 0s 396us/step - loss: 0.0066 - val_loss: 0.0168\n","\n","Epoch 00044: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n","Epoch 45/200\n","900/900 [==============================] - 0s 400us/step - loss: 0.0063 - val_loss: 0.0159\n","Epoch 46/200\n","900/900 [==============================] - 0s 401us/step - loss: 0.0060 - val_loss: 0.0159\n","Epoch 47/200\n","900/900 [==============================] - 0s 403us/step - loss: 0.0059 - val_loss: 0.0158\n","Epoch 48/200\n","900/900 [==============================] - 0s 428us/step - loss: 0.0057 - val_loss: 0.0162\n","Epoch 49/200\n","900/900 [==============================] - 0s 427us/step - loss: 0.0057 - val_loss: 0.0160\n","\n","Epoch 00049: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n","Epoch 50/200\n","900/900 [==============================] - 0s 408us/step - loss: 0.0055 - val_loss: 0.0159\n","Epoch 51/200\n","900/900 [==============================] - 0s 435us/step - loss: 0.0055 - val_loss: 0.0160\n","Epoch 52/200\n","900/900 [==============================] - 0s 392us/step - loss: 0.0055 - val_loss: 0.0158\n","Epoch 53/200\n","900/900 [==============================] - 0s 387us/step - loss: 0.0054 - val_loss: 0.0162\n","Epoch 54/200\n","900/900 [==============================] - 0s 429us/step - loss: 0.0054 - val_loss: 0.0158\n","\n","Epoch 00054: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n","Epoch 55/200\n","900/900 [==============================] - 0s 394us/step - loss: 0.0053 - val_loss: 0.0159\n","Epoch 56/200\n","900/900 [==============================] - 0s 385us/step - loss: 0.0053 - val_loss: 0.0158\n","Epoch 57/200\n","900/900 [==============================] - 0s 421us/step - loss: 0.0052 - val_loss: 0.0156\n","Epoch 58/200\n","900/900 [==============================] - 0s 398us/step - loss: 0.0052 - val_loss: 0.0157\n","Epoch 59/200\n","900/900 [==============================] - 0s 407us/step - loss: 0.0052 - val_loss: 0.0158\n","\n","Epoch 00059: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n","Epoch 60/200\n","900/900 [==============================] - 0s 390us/step - loss: 0.0052 - val_loss: 0.0158\n","Epoch 61/200\n","900/900 [==============================] - 0s 393us/step - loss: 0.0052 - val_loss: 0.0158\n","Epoch 62/200\n","900/900 [==============================] - 0s 406us/step - loss: 0.0052 - val_loss: 0.0157\n","Epoch 63/200\n","900/900 [==============================] - 0s 400us/step - loss: 0.0052 - val_loss: 0.0157\n","Epoch 64/200\n","900/900 [==============================] - 0s 388us/step - loss: 0.0051 - val_loss: 0.0157\n","\n","Epoch 00064: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n","Epoch 65/200\n","900/900 [==============================] - 0s 421us/step - loss: 0.0052 - val_loss: 0.0157\n","Epoch 66/200\n","900/900 [==============================] - 0s 382us/step - loss: 0.0052 - val_loss: 0.0157\n","Epoch 67/200\n","900/900 [==============================] - 0s 381us/step - loss: 0.0052 - val_loss: 0.0157\n","Epoch 68/200\n","900/900 [==============================] - 0s 395us/step - loss: 0.0051 - val_loss: 0.0158\n","Epoch 69/200\n","900/900 [==============================] - 0s 391us/step - loss: 0.0051 - val_loss: 0.0157\n","\n","Epoch 00069: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n","Epoch 70/200\n","900/900 [==============================] - 0s 383us/step - loss: 0.0051 - val_loss: 0.0157\n","Epoch 71/200\n","900/900 [==============================] - 0s 405us/step - loss: 0.0051 - val_loss: 0.0158\n","Epoch 72/200\n","900/900 [==============================] - 0s 384us/step - loss: 0.0051 - val_loss: 0.0158\n","Epoch 73/200\n","900/900 [==============================] - 0s 396us/step - loss: 0.0051 - val_loss: 0.0157\n","Epoch 74/200\n","900/900 [==============================] - 0s 397us/step - loss: 0.0051 - val_loss: 0.0158\n","\n","Epoch 00074: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n","Epoch 75/200\n","900/900 [==============================] - 0s 383us/step - loss: 0.0051 - val_loss: 0.0158\n","Epoch 76/200\n","900/900 [==============================] - 0s 394us/step - loss: 0.0051 - val_loss: 0.0157\n","Epoch 77/200\n","900/900 [==============================] - 0s 399us/step - loss: 0.0051 - val_loss: 0.0157\n","Epoch 78/200\n","900/900 [==============================] - 0s 415us/step - loss: 0.0051 - val_loss: 0.0158\n","Epoch 79/200\n","900/900 [==============================] - 0s 388us/step - loss: 0.0051 - val_loss: 0.0158\n","\n","Epoch 00079: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n","Epoch 80/200\n","900/900 [==============================] - 0s 404us/step - loss: 0.0051 - val_loss: 0.0158\n","Epoch 81/200\n","900/900 [==============================] - 0s 395us/step - loss: 0.0051 - val_loss: 0.0158\n","Epoch 82/200\n","900/900 [==============================] - 0s 407us/step - loss: 0.0051 - val_loss: 0.0157\n","Epoch 83/200\n","900/900 [==============================] - 0s 385us/step - loss: 0.0051 - val_loss: 0.0158\n","Epoch 84/200\n","900/900 [==============================] - 0s 389us/step - loss: 0.0051 - val_loss: 0.0157\n","\n","Epoch 00084: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n","Epoch 85/200\n","900/900 [==============================] - 0s 410us/step - loss: 0.0051 - val_loss: 0.0158\n","Epoch 86/200\n","900/900 [==============================] - 0s 398us/step - loss: 0.0051 - val_loss: 0.0158\n","Epoch 87/200\n","900/900 [==============================] - 0s 393us/step - loss: 0.0051 - val_loss: 0.0158\n","Epoch 88/200\n","900/900 [==============================] - 0s 425us/step - loss: 0.0051 - val_loss: 0.0158\n","Epoch 89/200\n","900/900 [==============================] - 0s 400us/step - loss: 0.0051 - val_loss: 0.0158\n","\n","Epoch 00089: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n","Epoch 90/200\n","900/900 [==============================] - 0s 389us/step - loss: 0.0051 - val_loss: 0.0158\n","Epoch 91/200\n","900/900 [==============================] - 0s 415us/step - loss: 0.0051 - val_loss: 0.0158\n","Epoch 92/200\n","900/900 [==============================] - 0s 396us/step - loss: 0.0051 - val_loss: 0.0158\n","Epoch 93/200\n","900/900 [==============================] - 0s 401us/step - loss: 0.0051 - val_loss: 0.0158\n","Epoch 94/200\n","900/900 [==============================] - 0s 427us/step - loss: 0.0051 - val_loss: 0.0158\n","\n","Epoch 00094: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n","Epoch 95/200\n","900/900 [==============================] - 0s 397us/step - loss: 0.0051 - val_loss: 0.0158\n","Epoch 96/200\n","900/900 [==============================] - 0s 393us/step - loss: 0.0050 - val_loss: 0.0158\n","Epoch 97/200\n","900/900 [==============================] - 0s 411us/step - loss: 0.0051 - val_loss: 0.0158\n","Epoch 98/200\n","900/900 [==============================] - 0s 397us/step - loss: 0.0051 - val_loss: 0.0158\n","Epoch 99/200\n","900/900 [==============================] - 0s 401us/step - loss: 0.0051 - val_loss: 0.0158\n","\n","Epoch 00099: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n","Epoch 100/200\n","900/900 [==============================] - 0s 388us/step - loss: 0.0051 - val_loss: 0.0158\n","Epoch 101/200\n","900/900 [==============================] - 0s 395us/step - loss: 0.0051 - val_loss: 0.0158\n","Epoch 102/200\n","900/900 [==============================] - 0s 404us/step - loss: 0.0051 - val_loss: 0.0158\n","Epoch 103/200\n","900/900 [==============================] - 0s 387us/step - loss: 0.0050 - val_loss: 0.0158\n","Epoch 104/200\n","900/900 [==============================] - 0s 392us/step - loss: 0.0051 - val_loss: 0.0158\n","\n","Epoch 00104: ReduceLROnPlateau reducing learning rate to 6.103515914901436e-08.\n","Epoch 105/200\n","900/900 [==============================] - 0s 408us/step - loss: 0.0051 - val_loss: 0.0158\n","Epoch 106/200\n","900/900 [==============================] - 0s 382us/step - loss: 0.0051 - val_loss: 0.0158\n","Epoch 107/200\n","900/900 [==============================] - 0s 416us/step - loss: 0.0051 - val_loss: 0.0158\n","Epoch 108/200\n","900/900 [==============================] - 0s 407us/step - loss: 0.0051 - val_loss: 0.0158\n","Epoch 109/200\n","900/900 [==============================] - 0s 384us/step - loss: 0.0051 - val_loss: 0.0158\n","\n","Epoch 00109: ReduceLROnPlateau reducing learning rate to 3.051757957450718e-08.\n","Epoch 110/200\n","900/900 [==============================] - 0s 389us/step - loss: 0.0051 - val_loss: 0.0158\n","Epoch 111/200\n","900/900 [==============================] - 0s 393us/step - loss: 0.0051 - val_loss: 0.0158\n","Epoch 112/200\n","900/900 [==============================] - 0s 380us/step - loss: 0.0051 - val_loss: 0.0158\n","Epoch 113/200\n","900/900 [==============================] - 0s 384us/step - loss: 0.0051 - val_loss: 0.0158\n","Epoch 114/200\n","900/900 [==============================] - 0s 395us/step - loss: 0.0051 - val_loss: 0.0158\n","\n","Epoch 00114: ReduceLROnPlateau reducing learning rate to 1.525878978725359e-08.\n","Epoch 115/200\n","900/900 [==============================] - 0s 380us/step - loss: 0.0051 - val_loss: 0.0158\n","Epoch 116/200\n","900/900 [==============================] - 0s 389us/step - loss: 0.0050 - val_loss: 0.0158\n","Epoch 117/200\n","900/900 [==============================] - 0s 393us/step - loss: 0.0051 - val_loss: 0.0158\n","Epoch 118/200\n","900/900 [==============================] - 0s 395us/step - loss: 0.0051 - val_loss: 0.0158\n","Epoch 119/200\n","900/900 [==============================] - 0s 403us/step - loss: 0.0050 - val_loss: 0.0158\n","\n","Epoch 00119: ReduceLROnPlateau reducing learning rate to 7.629394893626795e-09.\n","Epoch 120/200\n","900/900 [==============================] - 0s 398us/step - loss: 0.0051 - val_loss: 0.0158\n","Epoch 121/200\n","900/900 [==============================] - 0s 390us/step - loss: 0.0051 - val_loss: 0.0158\n","Epoch 122/200\n","900/900 [==============================] - 0s 401us/step - loss: 0.0051 - val_loss: 0.0158\n","Epoch 123/200\n","900/900 [==============================] - 0s 402us/step - loss: 0.0051 - val_loss: 0.0158\n","Epoch 124/200\n","900/900 [==============================] - 0s 394us/step - loss: 0.0051 - val_loss: 0.0158\n","\n","Epoch 00124: ReduceLROnPlateau reducing learning rate to 3.814697446813398e-09.\n","Epoch 125/200\n","900/900 [==============================] - 0s 402us/step - loss: 0.0051 - val_loss: 0.0158\n","Epoch 126/200\n","900/900 [==============================] - 0s 393us/step - loss: 0.0051 - val_loss: 0.0158\n","Epoch 127/200\n","900/900 [==============================] - 0s 393us/step - loss: 0.0051 - val_loss: 0.0158\n","Epoch 128/200\n","900/900 [==============================] - 0s 407us/step - loss: 0.0050 - val_loss: 0.0158\n","Epoch 129/200\n","900/900 [==============================] - 0s 381us/step - loss: 0.0051 - val_loss: 0.0158\n","\n","Epoch 00129: ReduceLROnPlateau reducing learning rate to 1.907348723406699e-09.\n","Epoch 130/200\n","900/900 [==============================] - 0s 384us/step - loss: 0.0051 - val_loss: 0.0158\n","Epoch 131/200\n","900/900 [==============================] - 0s 402us/step - loss: 0.0051 - val_loss: 0.0158\n","Epoch 132/200\n","900/900 [==============================] - 0s 391us/step - loss: 0.0051 - val_loss: 0.0158\n","Epoch 133/200\n","900/900 [==============================] - 0s 383us/step - loss: 0.0051 - val_loss: 0.0158\n","Epoch 134/200\n","900/900 [==============================] - 0s 401us/step - loss: 0.0051 - val_loss: 0.0158\n","\n","Epoch 00134: ReduceLROnPlateau reducing learning rate to 9.536743617033494e-10.\n","Epoch 135/200\n","900/900 [==============================] - 0s 389us/step - loss: 0.0051 - val_loss: 0.0158\n","Epoch 136/200\n","900/900 [==============================] - 0s 396us/step - loss: 0.0051 - val_loss: 0.0158\n","Epoch 137/200\n","900/900 [==============================] - 0s 399us/step - loss: 0.0051 - val_loss: 0.0158\n","Epoch 138/200\n","900/900 [==============================] - 0s 387us/step - loss: 0.0051 - val_loss: 0.0158\n","Epoch 139/200\n","900/900 [==============================] - 0s 400us/step - loss: 0.0051 - val_loss: 0.0158\n","\n","Epoch 00139: ReduceLROnPlateau reducing learning rate to 4.768371808516747e-10.\n","Epoch 140/200\n","900/900 [==============================] - 0s 406us/step - loss: 0.0051 - val_loss: 0.0158\n","Epoch 141/200\n","900/900 [==============================] - 0s 390us/step - loss: 0.0051 - val_loss: 0.0158\n","Epoch 142/200\n","900/900 [==============================] - 0s 387us/step - loss: 0.0051 - val_loss: 0.0158\n","Epoch 143/200\n","900/900 [==============================] - 0s 409us/step - loss: 0.0051 - val_loss: 0.0158\n","Epoch 144/200\n","900/900 [==============================] - 0s 386us/step - loss: 0.0051 - val_loss: 0.0158\n","\n","Epoch 00144: ReduceLROnPlateau reducing learning rate to 2.3841859042583735e-10.\n","Epoch 145/200\n","900/900 [==============================] - 0s 392us/step - loss: 0.0051 - val_loss: 0.0158\n","Epoch 146/200\n","900/900 [==============================] - 0s 382us/step - loss: 0.0051 - val_loss: 0.0158\n","Epoch 147/200\n","900/900 [==============================] - 0s 386us/step - loss: 0.0051 - val_loss: 0.0158\n","Epoch 148/200\n","900/900 [==============================] - 0s 401us/step - loss: 0.0051 - val_loss: 0.0158\n","Epoch 149/200\n","900/900 [==============================] - 0s 391us/step - loss: 0.0051 - val_loss: 0.0158\n","\n","Epoch 00149: ReduceLROnPlateau reducing learning rate to 1.1920929521291868e-10.\n","Epoch 150/200\n","900/900 [==============================] - 0s 387us/step - loss: 0.0051 - val_loss: 0.0158\n","Epoch 151/200\n","900/900 [==============================] - 0s 397us/step - loss: 0.0051 - val_loss: 0.0158\n","Epoch 152/200\n","900/900 [==============================] - 0s 384us/step - loss: 0.0051 - val_loss: 0.0158\n","Epoch 153/200\n","900/900 [==============================] - 0s 386us/step - loss: 0.0051 - val_loss: 0.0158\n","Epoch 154/200\n","900/900 [==============================] - 0s 392us/step - loss: 0.0051 - val_loss: 0.0158\n","\n","Epoch 00154: ReduceLROnPlateau reducing learning rate to 1e-10.\n","Epoch 155/200\n","900/900 [==============================] - 0s 391us/step - loss: 0.0051 - val_loss: 0.0158\n","Epoch 156/200\n","900/900 [==============================] - 0s 383us/step - loss: 0.0050 - val_loss: 0.0158\n","Epoch 157/200\n","900/900 [==============================] - 0s 408us/step - loss: 0.0051 - val_loss: 0.0158\n","Epoch 158/200\n","900/900 [==============================] - 0s 390us/step - loss: 0.0051 - val_loss: 0.0158\n","Epoch 159/200\n","900/900 [==============================] - 0s 380us/step - loss: 0.0051 - val_loss: 0.0158\n","\n","Epoch 00159: ReduceLROnPlateau reducing learning rate to 1e-10.\n","Epoch 160/200\n","900/900 [==============================] - 0s 393us/step - loss: 0.0051 - val_loss: 0.0158\n","Epoch 161/200\n","900/900 [==============================] - 0s 377us/step - loss: 0.0051 - val_loss: 0.0158\n","Epoch 162/200\n","900/900 [==============================] - 0s 383us/step - loss: 0.0051 - val_loss: 0.0158\n","Epoch 163/200\n","900/900 [==============================] - 0s 408us/step - loss: 0.0051 - val_loss: 0.0158\n","Epoch 164/200\n","900/900 [==============================] - 0s 382us/step - loss: 0.0051 - val_loss: 0.0158\n","\n","Epoch 00164: ReduceLROnPlateau reducing learning rate to 1e-10.\n","Epoch 165/200\n","900/900 [==============================] - 0s 378us/step - loss: 0.0051 - val_loss: 0.0158\n","Epoch 166/200\n","900/900 [==============================] - 0s 422us/step - loss: 0.0051 - val_loss: 0.0158\n","Epoch 167/200\n","900/900 [==============================] - 0s 384us/step - loss: 0.0051 - val_loss: 0.0158\n","Epoch 168/200\n","900/900 [==============================] - 0s 382us/step - loss: 0.0051 - val_loss: 0.0158\n","Epoch 169/200\n","900/900 [==============================] - 0s 394us/step - loss: 0.0051 - val_loss: 0.0158\n","\n","Epoch 00169: ReduceLROnPlateau reducing learning rate to 1e-10.\n","Epoch 170/200\n","900/900 [==============================] - 0s 388us/step - loss: 0.0051 - val_loss: 0.0158\n","Epoch 171/200\n","900/900 [==============================] - 0s 381us/step - loss: 0.0051 - val_loss: 0.0158\n","Epoch 172/200\n","900/900 [==============================] - 0s 395us/step - loss: 0.0051 - val_loss: 0.0158\n","Epoch 173/200\n","900/900 [==============================] - 0s 384us/step - loss: 0.0051 - val_loss: 0.0158\n","Epoch 174/200\n","900/900 [==============================] - 0s 387us/step - loss: 0.0051 - val_loss: 0.0158\n","\n","Epoch 00174: ReduceLROnPlateau reducing learning rate to 1e-10.\n","Epoch 175/200\n","900/900 [==============================] - 0s 393us/step - loss: 0.0051 - val_loss: 0.0158\n","Epoch 176/200\n","900/900 [==============================] - 0s 383us/step - loss: 0.0051 - val_loss: 0.0158\n","Epoch 177/200\n","900/900 [==============================] - 0s 387us/step - loss: 0.0051 - val_loss: 0.0158\n","Epoch 178/200\n","900/900 [==============================] - 0s 397us/step - loss: 0.0051 - val_loss: 0.0158\n","Epoch 179/200\n","900/900 [==============================] - 0s 388us/step - loss: 0.0051 - val_loss: 0.0158\n","\n","Epoch 00179: ReduceLROnPlateau reducing learning rate to 1e-10.\n","Epoch 180/200\n","900/900 [==============================] - 0s 392us/step - loss: 0.0051 - val_loss: 0.0158\n","Epoch 181/200\n","900/900 [==============================] - 0s 393us/step - loss: 0.0051 - val_loss: 0.0158\n","Epoch 182/200\n","900/900 [==============================] - 0s 379us/step - loss: 0.0051 - val_loss: 0.0158\n","Epoch 183/200\n","900/900 [==============================] - 0s 407us/step - loss: 0.0051 - val_loss: 0.0158\n","Epoch 184/200\n","900/900 [==============================] - 0s 393us/step - loss: 0.0050 - val_loss: 0.0158\n","\n","Epoch 00184: ReduceLROnPlateau reducing learning rate to 1e-10.\n","Epoch 185/200\n","900/900 [==============================] - 0s 394us/step - loss: 0.0050 - val_loss: 0.0158\n","Epoch 186/200\n","900/900 [==============================] - 0s 406us/step - loss: 0.0051 - val_loss: 0.0158\n","Epoch 187/200\n","900/900 [==============================] - 0s 390us/step - loss: 0.0051 - val_loss: 0.0158\n","Epoch 188/200\n","900/900 [==============================] - 0s 393us/step - loss: 0.0051 - val_loss: 0.0158\n","Epoch 189/200\n","900/900 [==============================] - 0s 422us/step - loss: 0.0051 - val_loss: 0.0158\n","\n","Epoch 00189: ReduceLROnPlateau reducing learning rate to 1e-10.\n","Epoch 190/200\n","900/900 [==============================] - 0s 399us/step - loss: 0.0051 - val_loss: 0.0158\n","Epoch 191/200\n","900/900 [==============================] - 0s 410us/step - loss: 0.0051 - val_loss: 0.0158\n","Epoch 192/200\n","900/900 [==============================] - 0s 420us/step - loss: 0.0051 - val_loss: 0.0158\n","Epoch 193/200\n","900/900 [==============================] - 0s 401us/step - loss: 0.0051 - val_loss: 0.0158\n","Epoch 194/200\n","900/900 [==============================] - 0s 419us/step - loss: 0.0051 - val_loss: 0.0158\n","\n","Epoch 00194: ReduceLROnPlateau reducing learning rate to 1e-10.\n","Epoch 195/200\n","900/900 [==============================] - 0s 409us/step - loss: 0.0051 - val_loss: 0.0158\n","Epoch 196/200\n","900/900 [==============================] - 0s 449us/step - loss: 0.0051 - val_loss: 0.0158\n","Epoch 197/200\n","900/900 [==============================] - 0s 413us/step - loss: 0.0051 - val_loss: 0.0158\n","Epoch 198/200\n","900/900 [==============================] - 0s 397us/step - loss: 0.0051 - val_loss: 0.0158\n","Epoch 199/200\n","900/900 [==============================] - 0s 398us/step - loss: 0.0051 - val_loss: 0.0158\n","\n","Epoch 00199: ReduceLROnPlateau reducing learning rate to 1e-10.\n","Epoch 200/200\n","900/900 [==============================] - 0s 415us/step - loss: 0.0051 - val_loss: 0.0158\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f2867df6160>"]},"metadata":{"tags":[]},"execution_count":76}]},{"cell_type":"code","metadata":{"id":"vszrDWhZaaiO","colab_type":"code","colab":{}},"source":["images = model.predict(noisy_train)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"scN0vKmxbkIz","colab_type":"code","colab":{}},"source":["img = 50\n","image = images[img].reshape(28,28)\n","real = train[img].reshape(28,28)\n","noisy = noisy_train[img].reshape(28,28)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"lesqHjbEcHfC","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":286},"outputId":"e5297730-7e01-4e16-9b3d-020460be11dc","executionInfo":{"status":"ok","timestamp":1563226731865,"user_tz":-330,"elapsed":1409,"user":{"displayName":"ayush singh","photoUrl":"","userId":"03115614203563270282"}}},"source":["plt.imshow(image)"],"execution_count":79,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<matplotlib.image.AxesImage at 0x7f2866c51ac8>"]},"metadata":{"tags":[]},"execution_count":79},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"hpgqwk_zcMGk","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":286},"outputId":"eb1eca5d-b5c9-42d3-edb5-c0bcb1b3075a","executionInfo":{"status":"ok","timestamp":1563226733697,"user_tz":-330,"elapsed":1281,"user":{"displayName":"ayush singh","photoUrl":"","userId":"03115614203563270282"}}},"source":["plt.imshow(real)"],"execution_count":80,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<matplotlib.image.AxesImage at 0x7f2866c2c128>"]},"metadata":{"tags":[]},"execution_count":80},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYII=\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"D9lXtdvIcQRG","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":286},"outputId":"504d9661-6542-497b-aa85-5daa1e0659b2","executionInfo":{"status":"ok","timestamp":1563226735441,"user_tz":-330,"elapsed":1281,"user":{"displayName":"ayush singh","photoUrl":"","userId":"03115614203563270282"}}},"source":["plt.imshow(noisy)"],"execution_count":81,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<matplotlib.image.AxesImage at 0x7f2866b82748>"]},"metadata":{"tags":[]},"execution_count":81},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"MgKcQakwcanw","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}